{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled12.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harsh-agar/E-Net/blob/master/Frustum_forward%20both.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knUV6yx6MZ3D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow-gpu==1.13.1\n",
        "!pip install hyperopt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjxXfMUYFzh1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/gdrive/My Drive/pointnet_orig/frustum-pointnets-master/models/tf_ops/sampling/')\n",
        "sys.path.append('/content/gdrive/My Drive/pointnet_orig/frustum-pointnets-master/models/tf_ops/grouping/')\n",
        "sys.path.append('/content/gdrive/My Drive/pointnet_orig/frustum-pointnets-master/models/tf_ops/3d_interpolation/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDLf1mqw2luC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_name = 'frustum_pointnets_v2'\n",
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import argparse\n",
        "import importlib\n",
        "import numpy as np\n",
        "import csv\n",
        "import tensorflow as tf\n",
        "import _pickle as pickle\n",
        "# BASE_DIR = os.path.dirname(os.path.abspath(__file__))\n",
        "# ROOT_DIR = os.path.dirname(BASE_DIR)\n",
        "BASE_DIR = os.path.dirname(\"/content/gdrive/My Drive/pointnet_orig/frustum-pointnets-master/\")\n",
        "ROOT_DIR = os.path.dirname(BASE_DIR)\n",
        "sys.path.append(BASE_DIR)\n",
        "sys.path.append(os.path.join(BASE_DIR, 'models'))\n",
        "from model_util import NUM_HEADING_BIN, NUM_SIZE_CLUSTER\n",
        "# import provider\n",
        "# from train_util import get_batch\n",
        "\n",
        "\n",
        "# Set training configurations\n",
        "BATCH_SIZE = 1\n",
        "NUM_POINT = 1024\n",
        "MODEL = importlib.import_module(model_name)\n",
        "NUM_CLASSES = 2\n",
        "NUM_CHANNEL = 4\n",
        "\n",
        "batch_size = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjdQxgg0wEZJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()\n",
        "with tf.Graph().as_default():\n",
        "  is_training_pl = tf.placeholder(tf.bool, shape=())\n",
        "  pointclouds_pl = tf.placeholder(tf.float32, shape=(BATCH_SIZE, NUM_POINT, 6))\n",
        "  batch_size = pointclouds_pl.get_shape()[0].value\n",
        "  num_point = pointclouds_pl.get_shape()[1].value        \n",
        "  is_training = tf.constant(False, dtype=tf.bool)\n",
        "\n",
        "  end_points = MODEL.get_model(pointclouds_pl, is_training_pl)\n",
        "\n",
        "  sess = tf.Session()\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  pc = np.loadtxt(open(\"/content/gdrive/My Drive/pointnet/PointnetEnhanced-master/data_sample.csv\", \"rb\"), delimiter=\",\")\n",
        "  ops = {'pointclouds_pl': pointclouds_pl,\n",
        "           'is_training_pl': is_training_pl}\n",
        "  feed_dict = {ops['pointclouds_pl']: [pc], ops['is_training_pl']: False}\n",
        "\n",
        "  batch_size_scores = sess.run(end_points, feed_dict=feed_dict)\n",
        "  # print(batch_size_scores.shape)\n",
        "  print(batch_size_scores)\n",
        "\n",
        "  for key, value in batch_size_scores.items() :\n",
        "      print (key)\n",
        "      print (value.shape)\n",
        "      print (\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
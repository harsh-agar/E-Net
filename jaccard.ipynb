{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPSPv0NdMPbTTjioR+C4Jlt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harsh-agar/E-Net/blob/master/jaccard.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rquUhwdUFaik",
        "outputId": "9fb3b740-023b-4cb8-cea9-e2b67985d0cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords \n",
        "from nltk.tokenize import word_tokenize \n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def get_jaccard_simmilarity(a, b): \n",
        "    c = a.intersection(b)\n",
        "    return float(len(c)) / (len(a) + len(b) - len(c))\n",
        "  \n",
        "X = (\"রুল মতে পোস্ট দিলে অবশ্যই এপ্রুভ হবে\")\n",
        "Y = (\"কিশোর গঞ্জের হাওরের পোস্ট নিষিদ্ধ করা হউক\")\n",
        "  \n",
        "# tokenization \n",
        "X_list = word_tokenize(X)  \n",
        "Y_list = word_tokenize(Y) \n",
        "  \n",
        "# sw contains the list of stopwords \n",
        "# sw = stopwords.words('english')  \n",
        "  \n",
        "# remove stop words from the string \n",
        "X_set = {w for w in X_list}\n",
        "Y_set = {w for w in Y_list}\n",
        "\n",
        "print(get_jaccard_simmilarity(X_set, Y_set))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "0.07692307692307693\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tf0EMHzsPtmH",
        "outputId": "6d357879-cbc3-43de-e16a-30321088ff31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JhvtEAcVbS5"
      },
      "source": [
        "import pandas as pd\n",
        "df_gt = pd.read_csv('/content/drive/My Drive/Zurana_Mehrin_Ruhi_GT_A1 - Sheet1.csv')"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3e7vxShvVxP6",
        "outputId": "b8962f5a-e08e-425f-9067-e5e016faee43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(df_gt['Text'])"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "299"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOUT9tSBaXM0",
        "outputId": "a6b95f21-e02f-4603-c04e-d133bba3ac62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        }
      },
      "source": [
        "!pip install cltk"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting cltk\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/20/42060504debda1fe85808d32ae82344e2efa4343dda15ec0151cf6bfe13d/cltk-0.1.121.tar.gz (625kB)\n",
            "\u001b[K     |████████████████████████████████| 634kB 7.2MB/s \n",
            "\u001b[?25hCollecting gitpython\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/d7/b2b0672e0331567157adf9281f41ee731c412ee518ca5e6552c27fa73c91/GitPython-3.1.9-py3-none-any.whl (159kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 22.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from cltk) (3.2.5)\n",
            "Collecting python-crfsuite\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/99/869dde6dbf3e0d07a013c8eebfb0a3d30776334e0097f8432b631a9a3a19/python_crfsuite-0.9.7-cp36-cp36m-manylinux1_x86_64.whl (743kB)\n",
            "\u001b[K     |████████████████████████████████| 747kB 33.4MB/s \n",
            "\u001b[?25hCollecting pyuca\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/88/aeeee34d88f841aca712a8c18fbd62a33eaad8f2dbe535e87f3c829b02f9/pyuca-1.2-py2.py3-none-any.whl (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 31.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from cltk) (3.13)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from cltk) (2019.12.20)\n",
            "Collecting whoosh\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ba/19/24d0f1f454a2c1eb689ca28d2f178db81e5024f42d82729a4ff6771155cf/Whoosh-2.7.4-py2.py3-none-any.whl (468kB)\n",
            "\u001b[K     |████████████████████████████████| 471kB 40.4MB/s \n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/11/d1800bca0a3bae820b84b7d813ad1eff15a48a64caea9c823fc8c1b119e8/gitdb-4.0.5-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 8.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk->cltk) (1.15.0)\n",
            "Collecting smmap<4,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/b0/9a/4d409a6234eb940e6a78dfdfc66156e7522262f5f2fecca07dc55915952d/smmap-3.0.4-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: cltk\n",
            "  Building wheel for cltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cltk: filename=cltk-0.1.121-cp36-none-any.whl size=711645 sha256=a93ac66185d8d139737f6fe29aae9638dcb622dc5f2143aed01488ea3e7cb4b6\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/c9/6b/e60acb6f511ebe008f3e961e894d57598517b25c4cbffbb70f\n",
            "Successfully built cltk\n",
            "Installing collected packages: smmap, gitdb, gitpython, python-crfsuite, pyuca, whoosh, cltk\n",
            "Successfully installed cltk-0.1.121 gitdb-4.0.5 gitpython-3.1.9 python-crfsuite-0.9.7 pyuca-1.2 smmap-3.0.4 whoosh-2.7.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEyLrg-FagO2",
        "outputId": "b82c2374-f374-4cb5-bf58-0a2e54710610",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# from bnlp.nltk_tokenizer import NLTK_Tokenizer\n",
        "from cltk.tokenize.sentence import TokenizeSentence\n",
        "line = \"আমি ভাত খাই\"\n",
        "\n",
        "tokenizer = TokenizeSentence('bengali')\n",
        "bengali_text_tokenize = tokenizer.tokenize(line)\n",
        "bengali_text_tokenize"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['আমি ভাত খাই']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHeFbARIYVnt",
        "outputId": "6692513b-9e48-4ebc-9d67-efe3ae35fbf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        }
      },
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize \n",
        "from nltk.corpus import stopwords \n",
        "from nltk import RegexpTokenizer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def get_jaccard_simmilarity(a, b): \n",
        "    c = a.intersection(b)\n",
        "    return float(len(c)) / (len(a) + len(b) - len(c))\n",
        "\n",
        "jaccard_thresh = 0.4\n",
        "df_gt = pd.read_csv('/content/drive/My Drive/Zurana_Mehrin_Ruhi_GT_A1 - Sheet1.csv')\n",
        "\n",
        "drop_list = np.empty(0)\n",
        "\n",
        "for i in range(len(df_gt['Text'])):\n",
        "  for j in range(i+1, len(df_gt['Text'])):\n",
        "    # tokenization\n",
        "    X_list = word_tokenize(df_gt['Text'][i]) \n",
        "    Y_list = word_tokenize(df_gt['Text'][j])\n",
        "\n",
        "    # remove stop words from the string \n",
        "    X_set = {w for w in X_list}\n",
        "    Y_set = {w for w in Y_list}\n",
        "\n",
        "    if get_jaccard_simmilarity(X_set, Y_set) >= jaccard_thresh:\n",
        "      drop_list = np.append(drop_list, j)\n",
        "df_gt = df_gt.drop(df_gt.index[np.unique(drop_list).astype(int)])\n",
        "df_gt.to_csv('content/drive/My Drive/out_Zurana_Mehrin_Ruhi_GT_A1.csv')"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-102-fafa3624f758>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m       \u001b[0mdrop_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mdf_gt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_gt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_gt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mdf_gt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'content/drive/My Drive/out_Zurana_Mehrin_Ruhi_GT_A1.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors)\u001b[0m\n\u001b[1;32m   3165\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3166\u001b[0m         )\n\u001b[0;32m-> 3167\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3169\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m                 \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m             )\n\u001b[1;32m    192\u001b[0m             \u001b[0mclose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors)\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0;31m# No explicit encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'content/drive/My Drive/out_Zurana_Mehrin_Ruhi_GT_A1.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCDFUzNVae0-"
      },
      "source": [
        "np.unique(drop_list)\n",
        "df_gt = df_gt.drop(df_gt.index[np.unique(drop_list).astype(int)])"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1rREiDZZZGT",
        "outputId": "28ba9446-0592-4426-ecfa-3080026a9997",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        }
      },
      "source": [
        "df_gt"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Link</th>\n",
              "      <th>Domain</th>\n",
              "      <th>Published_time</th>\n",
              "      <th>Subjectivity</th>\n",
              "      <th>Polarity</th>\n",
              "      <th>Annotator</th>\n",
              "      <th>Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>রুল মতে পোস্ট দিলে অবশ্যই এপ্রুভ হবে</td>\n",
              "      <td>https://www.facebook.com/groups/search/groups_...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1/5/2020</td>\n",
              "      <td>Subjective</td>\n",
              "      <td>Strongly Negative</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#REF!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>আমার ছবি কেনো এপ্রুভ হয়না ভাই</td>\n",
              "      <td>https://www.facebook.com/groups/search/groups_...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1/5/2020</td>\n",
              "      <td>Objective</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#REF!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>কিশোর গঞ্জের হাওরের পোস্ট নিষিদ্ধ করা হউক।</td>\n",
              "      <td>https://www.facebook.com/groups/search/groups_...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1/5/2020</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>হবু জামাই এর সন্ধানটাও দিন!!</td>\n",
              "      <td>https://www.facebook.com/groups/search/groups_...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1/5/2020</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ভিসা দিয়ে যাইতে হবে</td>\n",
              "      <td>https://www.facebook.com/groups/search/groups_...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4/5/2020</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>294</th>\n",
              "      <td>আপু, ঐ বাচ্চাটা কেমন আছে এখন ?</td>\n",
              "      <td>https://www.facebook.com/groups/DSExpl/permali...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5/26/2020</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>295</th>\n",
              "      <td>এতো এতো সভ্য শিক্ষত মানুষ এতো এতো নোংড়া গালী গ...</td>\n",
              "      <td>https://www.facebook.com/groups/DSExpl/permali...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5/26/2020</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>296</th>\n",
              "      <td>মানসিক অবস্থা যতটা খারাপ ছিলো এরচেয়েও বেশী ভার...</td>\n",
              "      <td>https://www.facebook.com/groups/DSExpl/permali...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5/26/2020</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>297</th>\n",
              "      <td>প্রত্যেকের নিজের জীবন সুন্দর করে গোছানোর অধিকা...</td>\n",
              "      <td>https://www.facebook.com/groups/DSExpl/permali...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5/26/2020</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>অতীত এবং বর্তমান, দুটোই দেখলাম</td>\n",
              "      <td>https://www.facebook.com/groups/DSExpl/permali...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5/26/2020</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>297 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  Text  ...   Time\n",
              "0                 রুল মতে পোস্ট দিলে অবশ্যই এপ্রুভ হবে  ...  #REF!\n",
              "1                        আমার ছবি কেনো এপ্রুভ হয়না ভাই  ...  #REF!\n",
              "2           কিশোর গঞ্জের হাওরের পোস্ট নিষিদ্ধ করা হউক।  ...    NaN\n",
              "3                         হবু জামাই এর সন্ধানটাও দিন!!  ...    NaN\n",
              "4                                  ভিসা দিয়ে যাইতে হবে  ...    NaN\n",
              "..                                                 ...  ...    ...\n",
              "294                     আপু, ঐ বাচ্চাটা কেমন আছে এখন ?  ...    NaN\n",
              "295  এতো এতো সভ্য শিক্ষত মানুষ এতো এতো নোংড়া গালী গ...  ...    NaN\n",
              "296  মানসিক অবস্থা যতটা খারাপ ছিলো এরচেয়েও বেশী ভার...  ...    NaN\n",
              "297  প্রত্যেকের নিজের জীবন সুন্দর করে গোছানোর অধিকা...  ...    NaN\n",
              "298                     অতীত এবং বর্তমান, দুটোই দেখলাম  ...    NaN\n",
              "\n",
              "[297 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRD1eS_Sf414"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled14.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNgvILNKgEJ0p0qTDCsnZzH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "62f9de069211442e877c10bb3f6f796f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_97a3e86fe68e4aa784d93785e036000e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ec741862be42437696d7ab223874f7ba",
              "IPY_MODEL_b8e46035e6fc4dd0a7750f983ccb420c"
            ]
          }
        },
        "97a3e86fe68e4aa784d93785e036000e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ec741862be42437696d7ab223874f7ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b94880161a4749c3bb5441c89551d2dc",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 8189,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 8189,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_abbf3191e2b941deaaaab9e0570edaf5"
          }
        },
        "b8e46035e6fc4dd0a7750f983ccb420c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_045bf897eb5c466e94fa8a3ba2b49461",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 8189/8189 [29:00&lt;00:00,  4.71it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_febbfc8179d14d6499c99fc91433cdd1"
          }
        },
        "b94880161a4749c3bb5441c89551d2dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "abbf3191e2b941deaaaab9e0570edaf5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "045bf897eb5c466e94fa8a3ba2b49461": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "febbfc8179d14d6499c99fc91433cdd1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harsh-agar/E-Net/blob/master/iNNvestigate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "988cBtGNytlY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "962f1b30-a9c3-494c-c480-813ed10793fe"
      },
      "source": [
        "%tensorflow_version 1.x\r\n",
        "import os\r\n",
        "import cv2\r\n",
        "from tqdm import tqdm_notebook\r\n",
        "import scipy.io as io"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVi_UsLM6If1",
        "outputId": "825c6e88-0c17-47c4-d07c-934a29ce5dc8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWOGwjTY6JYv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cbe3d3c-ab5b-42b0-dfec-e200fe2fbf2b"
      },
      "source": [
        "!wget -P '/content/drive/MyDrive/iNNvestigate' -c \"https://www.robots.ox.ac.uk/~vgg/data/flowers/102/102flowers.tgz\"\r\n",
        "!ls '/content/drive/MyDrive/iNNvestigate/'\r\n",
        "!tar -xvzf 'r/content/drive/MyDrive/iNNvestigate/102flowers.tgz' -C '/content/drive/MyDrive/iNNvestigate'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-01-10 15:13:06--  https://www.robots.ox.ac.uk/~vgg/data/flowers/102/102flowers.tgz\n",
            "Resolving www.robots.ox.ac.uk (www.robots.ox.ac.uk)... 129.67.94.2\n",
            "Connecting to www.robots.ox.ac.uk (www.robots.ox.ac.uk)|129.67.94.2|:443... connected.\n",
            "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n",
            "102flowers.tgz\tdataset  imagelabels.mat  innvestigate\tjpg  models\n",
            "tar (child): r/content/drive/MyDrive/iNNvestigate/102flowers.tgz: Cannot open: No such file or directory\n",
            "tar (child): Error is not recoverable: exiting now\n",
            "tar: Child returned status 2\n",
            "tar: Error is not recoverable: exiting now\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0QyaRyivArV",
        "outputId": "10ff8665-dc12-49f4-b7fa-03db5cb22bd4"
      },
      "source": [
        "!ls /content/drive/MyDrive/iNNvestigate"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "102flowers.tgz\tdataset  imagelabels.mat  jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPrmGreD8SD8",
        "outputId": "7f334997-80df-435f-eb4e-004457f18f6a"
      },
      "source": [
        "label_mat = io.loadmat('/content/drive/MyDrive/iNNvestigate/imagelabels.mat')\r\n",
        "len(label_mat['labels'][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8189"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116,
          "referenced_widgets": [
            "62f9de069211442e877c10bb3f6f796f",
            "97a3e86fe68e4aa784d93785e036000e",
            "ec741862be42437696d7ab223874f7ba",
            "b8e46035e6fc4dd0a7750f983ccb420c",
            "b94880161a4749c3bb5441c89551d2dc",
            "abbf3191e2b941deaaaab9e0570edaf5",
            "045bf897eb5c466e94fa8a3ba2b49461",
            "febbfc8179d14d6499c99fc91433cdd1"
          ]
        },
        "id": "5o4m18ow-bV2",
        "outputId": "1720cdfc-9d3c-4bbf-b0ea-ed401d172255"
      },
      "source": [
        "img_names = os.listdir('/content/drive/MyDrive/iNNvestigate/jpg/')\r\n",
        "img_names.sort()\r\n",
        "path = '/content/drive/MyDrive/iNNvestigate/dataset/'\r\n",
        "for i in tqdm_notebook(range(len(label_mat['labels'][0]))):\r\n",
        "  img = cv2.imread('/content/drive/MyDrive/iNNvestigate/jpg/'+img_names[i])\r\n",
        "  if i%5==0:\r\n",
        "    folder_path = path+'val/'+str(label_mat['labels'][0][i])\r\n",
        "  elif i%5==1:\r\n",
        "    folder_path = path+'test/'+str(label_mat['labels'][0][i])\r\n",
        "  else:\r\n",
        "    folder_path = path+'train/'+str(label_mat['labels'][0][i])\r\n",
        "  if not os.path.exists(folder_path):\r\n",
        "    os.makedirs(folder_path)\r\n",
        "  cv2.imwrite(folder_path+'/'+img_names[i], img) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "62f9de069211442e877c10bb3f6f796f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=8189.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9J5SreiXLZzM",
        "outputId": "5e291ea4-e7fa-4737-ce25-541f290588f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# from keras.applications import VGG16\r\n",
        "# from keras import Model\r\n",
        "# from keras.layers import Input, Flatten, Dense\r\n",
        "# import innvestigate\r\n",
        "\r\n",
        "# vgg = VGG16(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\r\n",
        "# lname = \"block5_conv2\"\r\n",
        "# last_vgg_layer = vgg.get_layer(lname)\r\n",
        "# vgg_partial = Model(inputs=vgg.input, outputs=last_vgg_layer.output, name=\"Partial_VGG16_\" + lname)\r\n",
        "# vgg_partial.trainable = False\r\n",
        "\r\n",
        "# inputs = Input(shape=(128, 128, 3))\r\n",
        "# # x = vgg_partial(inputs)\r\n",
        "# # x = Flatten()(x)\r\n",
        "# x = Flatten()(last_vgg_layer.get_output_at(0))\r\n",
        "\r\n",
        "# x = Dense(16, activation='relu')(x)\r\n",
        "# x = Dense(1, activation=None)(x)\r\n",
        "\r\n",
        "# model = Model(inputs=inputs, outputs=x)\r\n",
        "# print(model.summary())\r\n",
        "\r\n",
        "from keras.applications.vgg16 import VGG16 as PTModel\r\n",
        "from keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten, Input, Conv2D, multiply, LocallyConnected2D, Lambda\r\n",
        "from keras.models import Model\r\n",
        "\r\n",
        "in_lay = Input(shape=(224, 224, 3))\r\n",
        "base_pretrained_model = PTModel(input_shape = (224, 224, 3), \r\n",
        "                                include_top = True, \r\n",
        "                                weights = None,\r\n",
        "                                classes=102)\r\n",
        "\r\n",
        "model = base_pretrained_model\r\n",
        "model.summary()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 102)               417894    \n",
            "=================================================================\n",
            "Total params: 134,678,438\n",
            "Trainable params: 134,678,438\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHHRdEgtMXbG"
      },
      "source": [
        "# from keras.applications import VGG16\r\n",
        "# from keras import Model\r\n",
        "# from keras.layers import Input, Flatten, Dense\r\n",
        "\r\n",
        "# image_size=224\r\n",
        "\r\n",
        "# vgg = VGG16(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3))\r\n",
        "# lname = \"block5_conv2\"\r\n",
        "# last_vgg_layer = vgg.get_layer(lname)\r\n",
        "# vgg_partial = Model(inputs=vgg.input, outputs=last_vgg_layer.output, name=\"Partial_VGG16_\" + lname)\r\n",
        "# vgg_partial.trainable = False\r\n",
        "\r\n",
        "# last_vgg_layer.get_output_at(0)\r\n",
        "# # inputs = Input(shape=(image_size, image_size, 3))\r\n",
        "# # x = Flatten()(last_vgg_layer.get_output_at(0))\r\n",
        "# # x = Dense(16, activation='relu')(x)\r\n",
        "# # x = Dense(1, activation=None)(x)\r\n",
        "\r\n",
        "# # model = Model(inputs=inputs, outputs=x)\r\n",
        "# # model.summary()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0bq27IBPvZQ"
      },
      "source": [
        "# from keras.applications import VGG16\r\n",
        "# from keras import Model\r\n",
        "# from keras import Sequential\r\n",
        "# from keras.layers import Input, Flatten, Dense\r\n",
        "\r\n",
        "# image_size=224\r\n",
        "\r\n",
        "# vgg_conv = VGG16(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3))\r\n",
        "# lname = \"block5_conv2\"\r\n",
        "# last_vgg_layer = vgg_conv.get_layer(lname)\r\n",
        "\r\n",
        "# for layer in vgg_conv.layers[:]:\r\n",
        "#   layer.trainable = False\r\n",
        "# for layer in vgg_conv.layers:\r\n",
        "#   print(layer, layer.trainable)\r\n",
        "\r\n",
        "# model = Sequential()\r\n",
        "\r\n",
        "# # Add the vgg convolutional base model\r\n",
        "# # model.add(vgg_conv)\r\n",
        "# model.add(last_vgg_layer.get_output_at(0))\r\n",
        "\r\n",
        "# # Add new layers\r\n",
        "# model.add(Flatten())\r\n",
        "\r\n",
        "# model.add(Dense(1024, activation='relu'))\r\n",
        "# model.add(Dropout(0.5))\r\n",
        "# model.add(Dense(102, activation='softmax'))\r\n",
        "\r\n",
        "# # Show a summary of the model. Check the number of trainable parameters\r\n",
        "# model.summary()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHYBhorJ69pm"
      },
      "source": [
        "# from keras.applications import VGG16\r\n",
        "# from keras import Sequential\r\n",
        "# from keras.layers import Dense, Conv2D, MaxPool2D , Flatten, Dropout\r\n",
        "# from keras.preprocessing.image import ImageDataGenerator\r\n",
        "# import numpy as np\r\n",
        "\r\n",
        "# image_size=224\r\n",
        "\r\n",
        "# vgg_conv = VGG16(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3))\r\n",
        "\r\n",
        "# for layer in vgg_conv.layers[:]:\r\n",
        "#   layer.trainable = False\r\n",
        "# for layer in vgg_conv.layers:\r\n",
        "#   print(layer, layer.trainable)\r\n",
        "\r\n",
        "# lname = \"block5_conv2\"\r\n",
        "# last_vgg_layer = vgg_conv.get_layer(lname)\r\n",
        "\r\n",
        "# # Create the model\r\n",
        "# model = Sequential()\r\n",
        "\r\n",
        "# # Add the vgg convolutional base model\r\n",
        "# # model.add(vgg_conv)\r\n",
        "# model.add(last_vgg_layer.get_output_at(0))\r\n",
        "\r\n",
        "# # Add new layers\r\n",
        "# model.add(Flatten())\r\n",
        "\r\n",
        "# model.add(Dense(1024, activation='relu'))\r\n",
        "# model.add(Dropout(0.5))\r\n",
        "# model.add(Dense(102, activation='softmax'))\r\n",
        "\r\n",
        "# # Show a summary of the model. Check the number of trainable parameters\r\n",
        "# model.summary()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nWcqLSXxHvM"
      },
      "source": [
        "from keras.optimizers import RMSprop\r\n",
        "# # Configure the model for training\r\n",
        "model.compile(loss='categorical_crossentropy',\r\n",
        "              optimizer=RMSprop(lr=1e-4),\r\n",
        "              metrics=['categorical_accuracy'])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3X37GkaT8R_2",
        "outputId": "8f513ef0-1a70-4f44-ec35-f01dec4b0645"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\r\n",
        "\r\n",
        "# Load the normalized images\r\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\r\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\r\n",
        "\r\n",
        "# Change the batchsize according to your system RAM\r\n",
        "train_batchsize = 64\r\n",
        "val_batchsize = 64\r\n",
        "\r\n",
        "train_dir = '/content/drive/MyDrive/iNNvestigate/dataset/train'\r\n",
        "val_dir = '/content/drive/MyDrive/iNNvestigate/dataset/val'\r\n",
        "\r\n",
        "image_size = 224\r\n",
        "\r\n",
        "# Data generator for training data\r\n",
        "train_generator = train_datagen.flow_from_directory(\r\n",
        "        train_dir,\r\n",
        "        target_size=(image_size, image_size),\r\n",
        "        batch_size=train_batchsize,\r\n",
        "        class_mode='categorical')\r\n",
        "\r\n",
        "# Data generator for validation data\r\n",
        "validation_generator = validation_datagen.flow_from_directory(\r\n",
        "        val_dir,\r\n",
        "        target_size=(image_size, image_size),\r\n",
        "        batch_size=val_batchsize,\r\n",
        "        class_mode='categorical',\r\n",
        "        shuffle=False)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 4913 images belonging to 102 classes.\n",
            "Found 1638 images belonging to 102 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbzSYE-ND27P",
        "outputId": "ae63c721-71ff-4966-dd1d-98753f54de0c"
      },
      "source": [
        "train_generator.samples/train_generator.batch_size"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "76.765625"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ah64gJvGEDhv",
        "outputId": "3f55e5ae-4fef-46f0-ca1f-cb43a950b134"
      },
      "source": [
        "import os\r\n",
        "import keras\r\n",
        "fd = os.open(os.devnull, os.O_RDWR)\r\n",
        "# NB: even if stdin is closed, fd >= 0\r\n",
        "os.dup2(fd, 1)\r\n",
        "os.dup2(fd, 2)\r\n",
        "if fd > 2:\r\n",
        "    os.close(fd)\r\n",
        "\r\n",
        "callbacks = [\r\n",
        "        # saving model weights at checkpoints\r\n",
        "        keras.callbacks.ModelCheckpoint(\r\n",
        "            filepath          = os.path.join('/content/drive/MyDrive/iNNvestigate/models/','otcmodel_{epoch}.h5'),\r\n",
        "            save_best_only    = True,\r\n",
        "            monitor           = 'val_loss',\r\n",
        "            save_weights_only = True,\r\n",
        "            verbose           = 1\r\n",
        "        )]\r\n",
        "\r\n",
        "# Train the model\r\n",
        "history = model.fit(\r\n",
        "      train_generator,\r\n",
        "      steps_per_epoch=\r\n",
        "         train_generator.samples/train_generator.batch_size,\r\n",
        "      epochs=20,\r\n",
        "      validation_data=validation_generator, \r\n",
        "      validation_steps=\r\n",
        "         validation_generator.samples/validation_generator.batch_size,\r\n",
        "      verbose=1,\r\n",
        "      callbacks=callbacks,\r\n",
        ")\r\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Epoch 1/20\n",
            "76/76 [============================>.] - ETA: 0s - loss: 4.6181 - categorical_accuracy: 0.0322"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.6/keras/utils/data_utils.py:616: UserWarning: The input 18 could not be retrieved. It could be because a worker has died.\n",
            "  UserWarning)\n",
            "/tensorflow-1.15.2/python3.6/keras/utils/data_utils.py:616: UserWarning: The input 19 could not be retrieved. It could be because a worker has died.\n",
            "  UserWarning)\n",
            "/tensorflow-1.15.2/python3.6/keras/utils/data_utils.py:616: UserWarning: The input 20 could not be retrieved. It could be because a worker has died.\n",
            "  UserWarning)\n",
            "/tensorflow-1.15.2/python3.6/keras/utils/data_utils.py:616: UserWarning: The input 21 could not be retrieved. It could be because a worker has died.\n",
            "  UserWarning)\n",
            "/tensorflow-1.15.2/python3.6/keras/utils/data_utils.py:616: UserWarning: The input 22 could not be retrieved. It could be because a worker has died.\n",
            "  UserWarning)\n",
            "/tensorflow-1.15.2/python3.6/keras/utils/data_utils.py:616: UserWarning: The input 23 could not be retrieved. It could be because a worker has died.\n",
            "  UserWarning)\n",
            "/tensorflow-1.15.2/python3.6/keras/utils/data_utils.py:616: UserWarning: The input 24 could not be retrieved. It could be because a worker has died.\n",
            "  UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r77/76 [==============================] - 418s 5s/step - loss: 4.6176 - categorical_accuracy: 0.0322 - val_loss: 4.6886 - val_categorical_accuracy: 0.0220\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 4.68864, saving model to /content/drive/MyDrive/iNNvestigate/models/otcmodel_1.h5\n",
            "Epoch 2/20\n",
            "77/76 [==============================] - 57s 743ms/step - loss: 4.5383 - categorical_accuracy: 0.0283 - val_loss: 4.6192 - val_categorical_accuracy: 0.0311\n",
            "\n",
            "Epoch 00002: val_loss improved from 4.68864 to 4.61920, saving model to /content/drive/MyDrive/iNNvestigate/models/otcmodel_2.h5\n",
            "Epoch 3/20\n",
            "77/76 [==============================] - 58s 752ms/step - loss: 4.4356 - categorical_accuracy: 0.0434 - val_loss: 4.3355 - val_categorical_accuracy: 0.0446\n",
            "\n",
            "Epoch 00003: val_loss improved from 4.61920 to 4.33551, saving model to /content/drive/MyDrive/iNNvestigate/models/otcmodel_3.h5\n",
            "Epoch 4/20\n",
            "77/76 [==============================] - 57s 742ms/step - loss: 4.0678 - categorical_accuracy: 0.0643 - val_loss: 4.1492 - val_categorical_accuracy: 0.0891\n",
            "\n",
            "Epoch 00004: val_loss improved from 4.33551 to 4.14919, saving model to /content/drive/MyDrive/iNNvestigate/models/otcmodel_4.h5\n",
            "Epoch 5/20\n",
            "77/76 [==============================] - 57s 743ms/step - loss: 3.7283 - categorical_accuracy: 0.1111 - val_loss: 3.8455 - val_categorical_accuracy: 0.1245\n",
            "\n",
            "Epoch 00005: val_loss improved from 4.14919 to 3.84548, saving model to /content/drive/MyDrive/iNNvestigate/models/otcmodel_5.h5\n",
            "Epoch 6/20\n",
            "77/76 [==============================] - 58s 751ms/step - loss: 3.3875 - categorical_accuracy: 0.1525 - val_loss: 3.6324 - val_categorical_accuracy: 0.1716\n",
            "\n",
            "Epoch 00006: val_loss improved from 3.84548 to 3.63236, saving model to /content/drive/MyDrive/iNNvestigate/models/otcmodel_6.h5\n",
            "Epoch 7/20\n",
            "77/76 [==============================] - 58s 751ms/step - loss: 3.1026 - categorical_accuracy: 0.2111 - val_loss: 4.7805 - val_categorical_accuracy: 0.1325\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 3.63236\n",
            "Epoch 8/20\n",
            "77/76 [==============================] - 56s 732ms/step - loss: 2.8385 - categorical_accuracy: 0.2681 - val_loss: 3.3415 - val_categorical_accuracy: 0.2485\n",
            "\n",
            "Epoch 00008: val_loss improved from 3.63236 to 3.34149, saving model to /content/drive/MyDrive/iNNvestigate/models/otcmodel_8.h5\n",
            "Epoch 9/20\n",
            "77/76 [==============================] - 57s 746ms/step - loss: 2.4779 - categorical_accuracy: 0.3434 - val_loss: 3.1799 - val_categorical_accuracy: 0.2875\n",
            "\n",
            "Epoch 00009: val_loss improved from 3.34149 to 3.17989, saving model to /content/drive/MyDrive/iNNvestigate/models/otcmodel_9.h5\n",
            "Epoch 10/20\n",
            "77/76 [==============================] - 57s 744ms/step - loss: 2.0936 - categorical_accuracy: 0.4346 - val_loss: 2.7490 - val_categorical_accuracy: 0.2045\n",
            "\n",
            "Epoch 00010: val_loss improved from 3.17989 to 2.74896, saving model to /content/drive/MyDrive/iNNvestigate/models/otcmodel_10.h5\n",
            "Epoch 11/20\n",
            "77/76 [==============================] - 58s 748ms/step - loss: 1.5920 - categorical_accuracy: 0.5528 - val_loss: 3.6469 - val_categorical_accuracy: 0.3138\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 2.74896\n",
            "Epoch 12/20\n",
            "77/76 [==============================] - 56s 731ms/step - loss: 1.1340 - categorical_accuracy: 0.6756 - val_loss: 4.1646 - val_categorical_accuracy: 0.3272\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 2.74896\n",
            "Epoch 13/20\n",
            "77/76 [==============================] - 56s 734ms/step - loss: 0.6611 - categorical_accuracy: 0.8036 - val_loss: 4.1655 - val_categorical_accuracy: 0.3278\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 2.74896\n",
            "Epoch 14/20\n",
            "77/76 [==============================] - 56s 732ms/step - loss: 0.4304 - categorical_accuracy: 0.8781 - val_loss: 4.5673 - val_categorical_accuracy: 0.3004\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 2.74896\n",
            "Epoch 15/20\n",
            "77/76 [==============================] - 56s 725ms/step - loss: 0.3277 - categorical_accuracy: 0.9121 - val_loss: 5.1851 - val_categorical_accuracy: 0.3223\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 2.74896\n",
            "Epoch 16/20\n",
            "77/76 [==============================] - 56s 731ms/step - loss: 0.2482 - categorical_accuracy: 0.9351 - val_loss: 5.1295 - val_categorical_accuracy: 0.3101\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 2.74896\n",
            "Epoch 17/20\n",
            "77/76 [==============================] - 56s 726ms/step - loss: 0.2578 - categorical_accuracy: 0.9404 - val_loss: 4.8854 - val_categorical_accuracy: 0.3425\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 2.74896\n",
            "Epoch 18/20\n",
            "77/76 [==============================] - 56s 729ms/step - loss: 0.1935 - categorical_accuracy: 0.9483 - val_loss: 4.8417 - val_categorical_accuracy: 0.3492\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 2.74896\n",
            "Epoch 19/20\n",
            "77/76 [==============================] - 56s 726ms/step - loss: 0.1221 - categorical_accuracy: 0.9623 - val_loss: 5.6962 - val_categorical_accuracy: 0.3266\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 2.74896\n",
            "Epoch 20/20\n",
            "77/76 [==============================] - 56s 726ms/step - loss: 0.1291 - categorical_accuracy: 0.9672 - val_loss: 5.3447 - val_categorical_accuracy: 0.3657\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 2.74896\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqHvseYABusy"
      },
      "source": [
        "# pip install --upgrade pillow"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0DpQ4y8-cgn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a482eb36-1853-493b-89b7-9b1fc584bd03"
      },
      "source": [
        "all_ckpts = [file for file in os.listdir('/content/drive/MyDrive/iNNvestigate/models/') if ('_' in file) and ('.h5' in file)]\r\n",
        "ckpt_epochs = sorted(\r\n",
        "    [int(s) for ckpt_name in all_ckpts for s in ckpt_name.replace('_', '.').split('.') if s.isdigit()])\r\n",
        "ckpt_epoch = ckpt_epochs[-1]\r\n",
        "epoch = ckpt_epoch\r\n",
        "\r\n",
        "print('evaluating epoch %d' % ckpt_epoch)\r\n",
        "ckpt = [ckpt for ckpt in all_ckpts if str(ckpt_epoch) in ckpt]\r\n",
        "ckpt = ckpt[0]  # maybe otcmodel_5, otcmodel_50, otcmodel_51, ... in ckpt, if epoch = 5\r\n",
        "model.load_weights(os.path.join('/content/drive/MyDrive/iNNvestigate/models/', ckpt))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "evaluating epoch 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYwURXIUCD0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93dc43c3-3176-47f8-a3d5-5b7099e16441"
      },
      "source": [
        "import os\r\n",
        "try:\r\n",
        "    # %tensorflow_version only exists in Colab.\r\n",
        "    %tensorflow_version 1.x\r\n",
        "    IS_COLAB = True\r\n",
        "    if not os.path.exists('/content/drive/MyDrive/iNNvestigate/innvestigate'):\r\n",
        "        !git clone https://github.com/albermax/innvestigate.git /content/drive/MyDrive/iNNvestigate/innvestigate\r\n",
        "    !pip install /content/drive/MyDrive/iNNvestigate/innvestigate --no-deps\r\n",
        "    %cd /content/drive/MyDrive/iNNvestigate/innvestigate/innvestigate\r\n",
        "except Exception:\r\n",
        "    IS_COLAB = False"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing ./drive/MyDrive/iNNvestigate/innvestigate\n",
            "Building wheels for collected packages: innvestigate\n",
            "  Building wheel for innvestigate (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for innvestigate: filename=innvestigate-1.0.9-cp36-none-any.whl size=99902 sha256=bfd0c4ebca1c3f7bf5d5a719b0cfcd2748821fbbb0695c41cc6fe94ff938c016\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-_rgasgdz/wheels/ed/6a/81/273f7c945338bda571202a81a08fd5224b3faa94490ba35401\n",
            "Successfully built innvestigate\n",
            "Installing collected packages: innvestigate\n",
            "Successfully installed innvestigate-1.0.9\n",
            "/content/drive/MyDrive/iNNvestigate/innvestigate/innvestigate\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBS4lmQ31xWI",
        "outputId": "ddfec013-6274-4499-cef8-c4f29deed953"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "analyzer  applications\t__init__.py  layers.py\ttests  tools  utils\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r23YVBOaDIFv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d3e5e435-8ab0-4fe8-8ee1-8bd0543df4a0"
      },
      "source": [
        "# !pip install keras==2.3.1\r\n",
        "import innvestigate\r\n",
        "import innvestigate.utils as iutils\r\n",
        "innvestigate.__version__"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.0.9'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wc5qLHO5tGk"
      },
      "source": [
        "import matplotlib.pyplot as plot\r\n",
        "x= validation_generator.next()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyexi0n2FwBA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "625dfead-4f44-4942-da14-8c62f3fca761"
      },
      "source": [
        "image = x[0][0:1]\r\n",
        "\r\n",
        "# Stripping the softmax activation from the model\r\n",
        "model_wo_sm = iutils.keras.graph.model_wo_softmax(model)\r\n",
        "\r\n",
        "# Creating an analyzer\r\n",
        "gradient_analyzer = innvestigate.analyzer.Gradient(model_wo_sm)\r\n",
        "\r\n",
        "# Applying the analyzer\r\n",
        "analysis = gradient_analyzer.analyze(image)\r\n",
        "\r\n",
        "# Displaying the gradient\r\n",
        "plot.imshow(analysis.squeeze(), cmap='seismic', interpolation='nearest')\r\n",
        "plot.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TSdcRWm4NwN",
        "outputId": "fd3a7e83-1716-414e-ff8f-7189c6ba41c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow\r\n",
        "import keras as keras_standalone\r\n",
        "import tensorflow.keras as keras_tf\r\n",
        "print(\"keras_standalone:\", keras_standalone.__version__, \" keras_tf:\", keras_tf.__version__, \" tf:\", tensorflow.__version__)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "keras_standalone: 2.3.1  keras_tf: 2.2.4-tf  tf: 1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWOu1YVC_CBy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}